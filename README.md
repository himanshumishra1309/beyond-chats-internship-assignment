# ğŸ“ BeyondChats Article Scraper & LLM Enhancer

A full-stack application that scrapes articles from BeyondChats blog, searches for related content on Google, and uses AI (Google Gemini) to enhance and update the original articles with improved formatting and content.

---

##  Acknowledgment!

I would like to express my sincere gratitude to **BeyondChats** for providing me with this amazing opportunity to work on this assignment. This project has been an incredible learning experience, allowing me to explore web scraping, API integrations, LLM implementations, and full-stack development. Thank you for the chance to showcase my skills and grow as a developer!

---

## ğŸš€ Live Demo

ğŸ”— **Frontend**: [Live Link - Coming Soon](#)

---

## âœ¨ Features

- **Article Scraping**: Automatically scrapes the 5 oldest articles from BeyondChats blog
- **Google Search Integration**: Searches each article's title on Google and scrapes top 2 relevant results
- **AI-Powered Enhancement**: Uses Google Gemini LLM to update articles with improved formatting and content
- **Citation System**: Automatically adds references to source articles
- **Responsive UI**: Clean, professional frontend to view both original and updated articles
- **CRUD APIs**: Complete API endpoints for article management

---

## ğŸ› ï¸ Tech Stack

### Backend
| Technology | Purpose |
|------------|---------|
| Node.js | Runtime Environment |
| Express.js | Web Framework |
| MongoDB | Database |
| Mongoose | ODM for MongoDB |
| Cheerio | HTML Parsing (BeyondChats) |
| JSDOM + Readability | Content Extraction (Google Results) |
| SerpAPI | Google Search API |
| Google Gemini | LLM for Content Enhancement |
| Axios | HTTP Client |

### Frontend
| Technology | Purpose |
|------------|---------|
| React 19 | UI Library |
| Vite | Build Tool |
| Tailwind CSS v4 | Styling |
| React Router | Navigation |
| Axios | API Calls |

---

## ğŸ“Š Architecture / Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              BeyondChats Article Pipeline                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PHASE 1        â”‚     â”‚   PHASE 2        â”‚     â”‚   PHASE 3        â”‚
â”‚   Scrape Source  â”‚â”€â”€â”€â”€>â”‚   Enhance with   â”‚â”€â”€â”€â”€>â”‚   Display in     â”‚
â”‚                  â”‚     â”‚   LLM            â”‚     â”‚   Frontend       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                            DETAILED FLOW
                            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  BeyondChats Blog   â”‚
    â”‚  (Last 5 Articles)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼ Cheerio Scraping
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  BeyondChatsBlog    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  (MongoDB Schema)   â”‚                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
               â”‚                                     â”‚
               â”‚ For each article title              â”‚
               â–¼                                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚     SerpAPI         â”‚                          â”‚
    â”‚  (Google Search)    â”‚                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
               â”‚                                     â”‚
               â”‚ Top 2 URLs                          â”‚
               â–¼                                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚  JSDOM + Readabilityâ”‚                          â”‚
    â”‚  (Content Scraping) â”‚                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
               â”‚                                     â”‚
               â–¼                                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚ GoogleScrapedArticleâ”‚                          â”‚
    â”‚  (MongoDB Schema)   â”‚                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
               â”‚                                     â”‚
               â”‚ Original + References               â”‚
               â–¼                                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚   Google Gemini     â”‚                          â”‚
    â”‚   (LLM Processing)  â”‚                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
               â”‚                                     â”‚
               â”‚ Enhanced Content                    â”‚
               â–¼                                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚      Article        â”‚     References           â”‚
    â”‚  (MongoDB Schema)   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ REST APIs
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   React Frontend    â”‚
    â”‚  (Original + Updatedâ”‚
    â”‚     Articles)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Schema Relationships

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BeyondChatsBlog   â”‚       â”‚ GoogleScrapedArticleâ”‚       â”‚      Article        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ _id                 â”‚<â”€â”€â”€â”€â”€ â”‚ beyondChat_article_ â”‚       â”‚ originalArticleId   â”‚â”€â”€â”
â”‚ title               â”‚  ref  â”‚ _id                 â”‚       â”‚ referenceArticleIds â”‚â”€â”€â”¤
â”‚ slug                â”‚       â”‚ sourceUrl           â”‚<â”€â”€â”€â”€â”€â”€â”‚ title               â”‚  â”‚
â”‚ blogUrl             â”‚       â”‚ title               â”‚  ref  â”‚ contentHtml (LLM)   â”‚  â”‚
â”‚ contentText         â”‚       â”‚ contentText         â”‚       â”‚ contentText (LLM)   â”‚  â”‚
â”‚ contentHtml         â”‚       â”‚ contentHtml         â”‚       â”‚ citations           â”‚  â”‚
â”‚ author              â”‚       â”‚ excerpt             â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚ tags                â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                              â”‚
         â–²                                            ref                            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
beyondChatProject/
â”œâ”€â”€ client/                          # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/              # Reusable UI Components
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ArticleCard.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Loader.jsx
â”‚   â”‚   â”œâ”€â”€ pages/                   # Page Components
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx             # Updated Articles List
â”‚   â”‚   â”‚   â”œâ”€â”€ OriginalArticles.jsx # Original Articles List
â”‚   â”‚   â”‚   â”œâ”€â”€ ArticleDetail.jsx    # Updated Article View
â”‚   â”‚   â”‚   â””â”€â”€ OriginalArticleDetail.jsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js               # Axios API Configuration
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ index.css                # Tailwind Imports
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ server/                          # Node.js Backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controller/              # Route Controllers
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper.controller.js
â”‚   â”‚   â”‚   â”œâ”€â”€ article.controller.js
â”‚   â”‚   â”‚   â””â”€â”€ originalArticle.controller.js
â”‚   â”‚   â”œâ”€â”€ model/                   # MongoDB Schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ beyondChatsBlog.model.js
â”‚   â”‚   â”‚   â”œâ”€â”€ googleScrapedArticle.model.js
â”‚   â”‚   â”‚   â””â”€â”€ article.model.js
â”‚   â”‚   â”œâ”€â”€ route/                   # API Routes
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper.route.js
â”‚   â”‚   â”‚   â”œâ”€â”€ article.route.js
â”‚   â”‚   â”‚   â””â”€â”€ originalArticle.route.js
â”‚   â”‚   â”œâ”€â”€ scripts/                 # Scraping & LLM Logic
â”‚   â”‚   â”‚   â”œâ”€â”€ beyondChatScrape.js
â”‚   â”‚   â”‚   â”œâ”€â”€ googleScrape.js
â”‚   â”‚   â”‚   â””â”€â”€ llmResult.js
â”‚   â”‚   â”œâ”€â”€ utils/                   # Utility Classes
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â””â”€â”€ index.js             # MongoDB Connection
â”‚   â”‚   â”œâ”€â”€ app.js                   # Express App Setup
â”‚   â”‚   â””â”€â”€ index.js                 # Server Entry Point
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Local Setup Instructions

### Prerequisites

- Node.js (v18 or higher)
- npm or yarn
- MongoDB Atlas Account
- SerpAPI Account
- Google AI Studio Account

---

### ğŸ”§ Backend Setup

#### Step 1: Navigate to Server Directory

```bash
cd server
```

#### Step 2: Create Environment File

Create a `.env` file in the `server` directory:

```bash
# Copy the example file
cp .env.example .env
```

Or manually create `.env` and copy contents from `.env.example`:

```env
PORT = 8000
MONGODB_URI=mongodb+srv://<db_name>:<db_passowrd>@cluster0.2w959aw.mongodb.net
CORS_ORIGIN=*
ACCESS_TOKEN_SECRET = acCeSsToKeN-madeByHimansHuMisHRa
ACCESS_TOKEN_EXPIRY = 1d
REFRESH_TOKEN_SECRET = refREsHToKeN-madeByHimansHuMisHRa
REFRESH_TOKEN_EXPIRY = 10d
SERP_API_KEY= your_serp_api_key
GEMINI_API_KEY=your_gemini_api_key
```

#### Step 3: Configure MongoDB Atlas

1. Go to [MongoDB Atlas](https://www.mongodb.com/atlas)
2. Create an account or log in
3. Click **"New Project"** â†’ Enter project name â†’ Click **"Next"** â†’ **"Create Project"**
4. Click **"Create Cluster"** â†’ Select **FREE plan** â†’ Click **"Create Deployment"**
5. A popup will appear:
   - Enter a **username**
   - Enter a **password** (âš ï¸ **Copy this password for later!**)
   - Click **"Create Database User"**
6. Click **"Choose a Connection Method"** â†’ Select **"Compass"**
7. Copy the MongoDB connection string (looks like: `mongodb+srv://username:<db_password>@cluster0.xxxxx.mongodb.net`)
8. Paste it in your `.env` file as `MONGODB_URI`
9. Replace `<db_password>` with the password you copied earlier

#### Step 4: Configure SerpAPI

1. Go to [SerpAPI](https://serpapi.com/)
2. Click **"Register"** â†’ Sign up with Google
3. Verify your email and phone number
4. Log in and go to your **Dashboard** (top right corner)
5. Find **"Your Private API Key"**
6. Copy the API key and paste it in `.env` as `SERP_API_KEY`

#### Step 5: Configure Google Gemini

1. Go to [Google AI Studio](https://aistudio.google.com/)
2. Click **"Get Started"** (top right)
3. From the left sidebar, navigate to **Dashboard** â†’ **API Keys**
4. Create or copy your API key
5. Paste it in `.env` as `GEMINI_API_KEY`

#### Step 6: Install Dependencies & Run Server

```bash
npm install
npm run dev
```

âœ… Server will start on **http://localhost:8000**

---

### ğŸ¨ Frontend Setup

#### Step 1: Navigate to Client Directory

```bash
cd client
```

#### Step 2: Install Dependencies

```bash
npm install
```

Or if you face peer dependency issues:

```bash
npm install --force
```

#### Step 3: Environment Configuration (Optional)

For **local development**, no configuration is needed - it automatically uses `http://localhost:8000/api/v1`.


#### Step 4: Run Development Server

```bash
npm run dev
```

âœ… Frontend will start on **http://localhost:5173**

---

## ğŸ”„ How to Run the Scraping Pipeline

Use **Postman** or any API client to trigger the scraping process:

### Step 1: Scrape BeyondChats Articles

```
GET http://localhost:8000/api/v1/scraper/scrape-beyond-chats
```

This fetches the **5 oldest articles** from BeyondChats blog and stores them in `BeyondChatsBlog` collection.

### Step 2: Scrape Google for Related Articles

```
GET http://localhost:8000/api/v1/scraper/scrape-google-article
```

This searches each article's title on Google, scrapes the **top 2 relevant URLs**, and stores them in `GoogleScrapedArticle` collection.

### Step 3: Generate LLM-Enhanced Articles

```
GET http://localhost:8000/api/v1/scraper/llm-response
```

This calls **Google Gemini** to update each original article with improved formatting and content similar to the top-ranking Google results. Enhanced articles are stored in `Article` collection with citations.

â³ **Note**: This step may take a few minutes as the LLM processes each article.

### Step 4: View Results

Open **http://localhost:5173** to see both:
- **Original Articles** - Scraped directly from BeyondChats
- **Updated Articles** - AI-enhanced versions with citations

---

## ğŸ“¡ API Endpoints

### Scraper Routes (`/api/v1/scraper`)

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/scrape-beyond-chats` | Scrape 5 oldest BeyondChats articles |
| GET | `/scrape-google-article` | Search & scrape Google results |
| GET | `/llm-response` | Generate LLM-enhanced articles |

### Updated Articles Routes (`/api/v1/updated-articles`)

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/articles` | Get all LLM-updated articles |
| GET | `/article/:id` | Get updated article by ID (with references) |
| PUT | `/article/:id` | Update an article |
| DELETE | `/article/:id` | Delete an article |

### Original Articles Routes (`/api/v1/original-articles`)

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/articles` | Get all original BeyondChats articles |
| GET | `/article/:id` | Get original article by ID |
| PUT | `/article/:id` | Update original article |
| DELETE | `/article/:id` | Delete original article |

---

## ğŸ“¸ Screenshots

### Home Page - Updated Articles
<img width="1901" height="874" alt="Screenshot 2025-12-31 200733" src="https://github.com/user-attachments/assets/5aeeeaf3-18fb-46de-91dd-2ca463ded210" />


### Original Articles
<img width="1896" height="877" alt="Screenshot 2025-12-31 200822" src="https://github.com/user-attachments/assets/3170c46a-e264-447d-8d60-3c587eb18cb5" />


### Article Detail View
<img width="1903" height="881" alt="Screenshot 2025-12-31 200853" src="https://github.com/user-attachments/assets/12d7e283-6297-4ff8-9307-27cd28b833ce" />


---

## ğŸ¯ Assignment Completion Checklist

### Phase 1 âœ…
- [x] Scrape 5 oldest articles from BeyondChats blog
- [x] Store articles in MongoDB database
- [x] Create CRUD APIs for articles

### Phase 2 âœ…
- [x] Search article titles on Google using SerpAPI
- [x] Scrape top 2 relevant articles from Google results
- [x] Call LLM (Google Gemini) to enhance original articles
- [x] Make formatting/content similar to top-ranking articles
- [x] Add citations for reference articles at the bottom

### Phase 3 âœ…
- [x] Create React frontend with responsive UI
- [x] Display both original and updated articles
- [x] Professional, clean design with Tailwind CSS

---

## ğŸ‘¨â€ğŸ’» Author

**Himanshu Mishra**

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## Thank You!

Thank you **BeyondChats** for this wonderful opportunity. It was an amazing experience building this project!
